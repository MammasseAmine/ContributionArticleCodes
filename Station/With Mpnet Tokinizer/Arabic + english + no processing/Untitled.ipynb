{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c6c8fa-b766-43c3-9409-b996526f7993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9463df5-1758-4098-864f-212f6a062e05",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4697fe-35e3-4238-b930-16d2dda15c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from bs4 import BeautifulSoup\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch.ao.quantization as quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485a957-0505-497e-af60-fd28acbc4c2c",
   "metadata": {},
   "source": [
    "# ADD THE SEED (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf56cdb-1c18-4a42-9bd9-5f165fbe55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42  \n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Ensure deterministic behavior in PyTorch (may slow down training)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe79fb97-a18f-4015-bedf-abce3f02ceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNHINGED Trump Supporters Visit DC For Inaugu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إغلاق دائرة تنفيذ بعبدا بسبب كورونا أعلن أمين ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بيراميدز يعود لفندق إقامته في دار السلام عادت ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lindsay Lohan&lt;U+2019&gt;s Strange Accent: Another...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الإفتاء المصرية: غدًا أول أيام شهر شعبان لعام ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453149</th>\n",
       "      <td>طقس اليوم.. نزول قطرات مطرية بمجموعة من مناطق ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453150</th>\n",
       "      <td>توقيف مصري أثار فيديو يظهر تحرشه بطفلة استنكار...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453151</th>\n",
       "      <td>رئيس المجلس الأعلى للقضاء يستقبل المبعوث الأمم...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453152</th>\n",
       "      <td>في ظرف 24 ساعة: 4 آلاف مكالمة على 190.. والوضع...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453153</th>\n",
       "      <td>HOW TRUMP RESPONDED WHEN 200 Gulf War Marines ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                statement  Label\n",
       "0        UNHINGED Trump Supporters Visit DC For Inaugu...      1\n",
       "1       إغلاق دائرة تنفيذ بعبدا بسبب كورونا أعلن أمين ...      1\n",
       "2       بيراميدز يعود لفندق إقامته في دار السلام عادت ...      1\n",
       "3       Lindsay Lohan<U+2019>s Strange Accent: Another...      1\n",
       "4       الإفتاء المصرية: غدًا أول أيام شهر شعبان لعام ...      0\n",
       "...                                                   ...    ...\n",
       "453149  طقس اليوم.. نزول قطرات مطرية بمجموعة من مناطق ...      0\n",
       "453150  توقيف مصري أثار فيديو يظهر تحرشه بطفلة استنكار...      0\n",
       "453151  رئيس المجلس الأعلى للقضاء يستقبل المبعوث الأمم...      0\n",
       "453152  في ظرف 24 ساعة: 4 آلاف مكالمة على 190.. والوضع...      1\n",
       "453153  HOW TRUMP RESPONDED WHEN 200 Gulf War Marines ...      1\n",
       "\n",
       "[453154 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"myArabicEnglishGlobalFakeNewsDataWithoutFeaturesWithoutPreprocessing.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9011b6da-1d62-4590-979a-d13834a18d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b434f6c2-bfe2-47db-be1b-13320a61cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'statement'\n",
    "labels = df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25858f-4e10-40b0-bde6-4d035cd6e2af",
   "metadata": {},
   "source": [
    "# Initialize Tokenizers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8796c446-4d1a-416d-a8b1-7cf5b45d37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "mpnet_model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11b36c9-a248-4620-9e88-faac8f4d426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361407d3-3315-43db-be85-444ecba2b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move mpnet_model to device\n",
    "mpnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0aa872-3cbb-4228-977a-b9c15e5387aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, model):\n",
    "        self.texts = texts.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model =  model\n",
    "        self.model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        # Tokenize the text with truncation but no padding\n",
    "        inputs = mpnet_tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            padding=False,        # No padding here (dynamic padding in collate_fn)\n",
    "            truncation=True,      # Truncate to max_length\n",
    "            max_length=512        # Set a maximum length (in bytes)\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # Shape [seq_len]\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)  # Shape [seq_len]\n",
    "\n",
    "        # Move inputs to the same device as the model\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        # Get embeddings from the model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n",
    "            embeddings = outputs.last_hidden_state.squeeze(0)  # Shape [seq_len, hidden_dim]\n",
    "\n",
    "        # Move data back to CPU for DataLoader\n",
    "        embeddings = embeddings.cpu()\n",
    "        attention_mask = attention_mask.cpu()\n",
    "\n",
    "        return {\n",
    "            'embeddings': embeddings,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a46f66-e8d1-4042-bc4e-d54d08940212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # Extract individual components\n",
    "    embeddings_list = [item['embeddings'] for item in batch]\n",
    "    attention_masks_list = [item['attention_mask'] for item in batch]\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "\n",
    "    # Find max sequence length in the batch\n",
    "    max_seq_len = max([embeddings.size(0) for embeddings in embeddings_list])\n",
    "\n",
    "    # Initialize padded tensors\n",
    "    batch_size = len(batch)\n",
    "    hidden_dim = embeddings_list[0].size(1)\n",
    "\n",
    "    padded_embeddings = torch.zeros(batch_size, max_seq_len, hidden_dim)\n",
    "    padded_attention_masks = torch.zeros(batch_size, max_seq_len, dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        seq_len = embeddings_list[i].size(0)\n",
    "        padded_embeddings[i, :seq_len, :] = embeddings_list[i]\n",
    "        padded_attention_masks[i, :seq_len] = attention_masks_list[i]\n",
    "\n",
    "    return {\n",
    "        'embeddings': padded_embeddings,\n",
    "        'attention_mask': padded_attention_masks,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d702dd-4812-4371-bd0e-b60d862e5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fourier Positional Encoding\n",
    "class FourierPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, temperature=10000):\n",
    "        super(FourierPositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.register_buffer(\n",
    "            'freq_bands',\n",
    "            torch.linspace(0, 1, steps=d_model // 2) * temperature\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        positions = torch.arange(seq_len, dtype=torch.float, device=x.device).unsqueeze(-1)  # Shape [seq_len, 1]\n",
    "        proj = positions * self.freq_bands  # Shape [seq_len, d_model/2]\n",
    "        sin_encoding = torch.sin(proj)\n",
    "        cos_encoding = torch.cos(proj)\n",
    "        encoding = torch.cat([sin_encoding, cos_encoding], dim=-1)\n",
    "        encoding = encoding.unsqueeze(0)  # Shape [1, seq_len, d_model]\n",
    "        return x + encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edb28dc6-19d0-4e26-a294-60ed7c31e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model components\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = (normalized_shape,)\n",
    "        self.normalized_shape = tuple(normalized_shape)\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "        if self.elementwise_affine:\n",
    "            self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "            self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dims = tuple(-(i + 1) for i in range(len(self.normalized_shape)))\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        var = x.var(dim=dims, unbiased=False, keepdim=True)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        if self.elementwise_affine:\n",
    "            x = x * self.weight + self.bias\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c58da76-020c-4e1f-a54f-0e59f298fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InfiniAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super(InfiniAttention, self).__init__()\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None, key_padding_mask=None):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # Transform to query, key, value\n",
    "        q = self.query(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)  # [B, nhead, T, d_head]\n",
    "        k = self.key(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)\n",
    "        v = self.value(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(k.size(-1))  # [B, nhead, T, T]\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            # key_padding_mask shape: [B, T] -> [B, 1, 1, T]\n",
    "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_scores = attn_scores.masked_fill(key_padding_mask, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, v)  # [B, nhead, T, d_head]\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beb9f9dc-a730-40a7-85e1-3e02e3a5a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5f97223-4c68-4182-9628-1c0c55c530ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = InfiniAttention(d_model, nhead, dropout)\n",
    "        self.ffn = FeedForwardNetwork(d_model, dim_feedforward, dropout)\n",
    "        self.norm1 = LayerNormalization(d_model)\n",
    "        self.norm2 = LayerNormalization(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # Self-attention\n",
    "        residual = src\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.self_attn(src, mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
    "        src = residual + self.dropout(src2)\n",
    "\n",
    "        # Feed-forward\n",
    "        residual = src\n",
    "        src = self.norm2(src)\n",
    "        src2 = self.ffn(src)\n",
    "        src = residual + self.dropout(src2)\n",
    "        return src\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, num_layers, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1043330-ad4a-4705-b39f-3e4b58ed72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, dropout_rate=0.5):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(input_dim, input_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_dim // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ada27f2-a499-43b4-a30f-8194d7989aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization import QConfig, default_qconfig, default_per_channel_qconfig\n",
    "from torch.ao.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver\n",
    "\n",
    "def prepare_model_for_qat(model):\n",
    "    \"\"\"\n",
    "    Prepares the model for quantization-aware training.\n",
    "    \"\"\"\n",
    "    # Define qconfig\n",
    "    qconfig = QConfig(\n",
    "        activation=MovingAverageMinMaxObserver.with_args(dtype=torch.quint8),\n",
    "        weight=MinMaxObserver.with_args(dtype=torch.qint8)\n",
    "    )\n",
    "\n",
    "    # Apply qconfig to the model\n",
    "    model.qconfig = qconfig\n",
    "    # Skip fusing layers since this is a custom model\n",
    "    quantization.prepare_qat(model, inplace=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "905eaf29-88ce-4cc4-8550-60a51186cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=768, hidden_dim=256, num_classes=2, num_encoder_layers=6):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.quant = torch.ao.quantization.QuantStub()  # Add QuantStub\n",
    "        self.pos_encoder = FourierPositionalEncoding(embedding_dim)\n",
    "        self.encoder = Encoder(embedding_dim, nhead=8, dim_feedforward=hidden_dim * 4, num_layers=num_encoder_layers)\n",
    "        self.classifier = ClassifierHead(embedding_dim, num_classes)\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()  # Add DeQuantStub\n",
    "\n",
    "    def forward(self, embeddings, attention_mask):\n",
    "        # Apply quantization\n",
    "        embeddings = self.quant(embeddings)\n",
    "        \n",
    "        # Apply positional encoding\n",
    "        embeddings = self.pos_encoder(embeddings)\n",
    "        \n",
    "        # Create src_key_padding_mask from attention_mask\n",
    "        src_key_padding_mask = attention_mask == 0\n",
    "        \n",
    "        # Pass through the encoder\n",
    "        encoder_output = self.encoder(embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Masked mean pooling\n",
    "        masked_encoder_output = encoder_output * attention_mask.unsqueeze(-1)\n",
    "        sum_embeddings = masked_encoder_output.sum(dim=1)\n",
    "        lengths = attention_mask.sum(dim=1).unsqueeze(-1)\n",
    "        pooled_output = sum_embeddings / lengths\n",
    "        \n",
    "        # Classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Dequantize the output\n",
    "        logits = self.dequant(logits)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccd47179-0c7f-44dc-8295-757d8858e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and apply QAT\n",
    "model = CombinedModel().to(device)\n",
    "model = prepare_model_for_qat(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b6c6d89-c872-408f-a151-bdf9b9488c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data and create DataLoaders\n",
    "def split_data(texts, labels, tokenizer, model, train_size=0.8, val_size=0.1, test_size=0.1, batch_size=64):\n",
    "    assert train_size + val_size + test_size == 1, \"Split proportions must sum to 1.\"\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = FakeNewsDataset(texts, labels, tokenizer, model)\n",
    "\n",
    "    # Split the dataset\n",
    "    train_len = int(train_size * len(dataset))\n",
    "    val_len = int(val_size * len(dataset))\n",
    "    test_len = len(dataset) - train_len - val_len\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "    # Create DataLoaders with the custom collate function\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader, val_dataloader, test_dataloader = split_data(\n",
    "    df[text_column],\n",
    "    labels,\n",
    "    mpnet_tokenizer,\n",
    "    mpnet_model,\n",
    "    batch_size=64  # Adjust batch size as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbfb70b3-f05e-4441-9206-fbba103bbb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (quant): QuantStub()\n",
       "  (pos_encoder): FourierPositionalEncoding()\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (self_attn): InfiniAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ffn): FeedForwardNetwork(\n",
       "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
       "          (activation): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ClassifierHead(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc1): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the model and move it to device\n",
    "model = CombinedModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba9fffe0-3141-4fb7-b208-1b34bb6c7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up optimizer and scheduler\n",
    "def setup_optimizer_and_scheduler(model, learning_rate=2e-5, step_size=7, gamma=0.1, weight_decay=0.01):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss function for binary classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer, scheduler = setup_optimizer_and_scheduler(model)\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Initialize GradScaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Wrap the dataloader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        embeddings = batch['embeddings'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use autocast for mixed precision (CUDA)\n",
    "        with autocast():\n",
    "            outputs = model(embeddings, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Scale the loss and backpropagate\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate loss and predictions\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        # Update the progress bar description with the current loss\n",
    "        progress_bar.set_description(f\"Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average loss and metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bff1a1f-97af-49ae-bff0-838effd02f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            embeddings = batch['embeddings'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(embeddings, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37610471-098c-441b-8586-373ef9cff70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify training_loop to include early stopping\n",
    "def training_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, num_epochs, device, patience=3):\n",
    "    best_val_f1 = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss, train_accuracy, train_f1 = train_one_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        val_loss, val_accuracy, val_f1, val_preds, val_labels = evaluate(model, val_dataloader, criterion, device)  # Capture all return values\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print training and validation metrics\n",
    "        print(f\"Epoch: {epoch+1:02}\")\n",
    "        print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}% | Train F1: {train_f1:.3f}\")\n",
    "        print(f\"\\tVal. Loss: {val_loss:.3f} | Val. Acc: {val_accuracy*100:.2f}% | Val. F1: {val_f1:.3f}\")\n",
    "\n",
    "        # Check for improvement in validation F1 score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Save the best model checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "                'val_preds': val_preds,  # Save validation predictions\n",
    "                'val_labels': val_labels,  # Save validation labels\n",
    "            }, 'best_model_checkpoint.pth')\n",
    "            print(\"\\tModel saved!\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs.\")\n",
    "                break\n",
    "\n",
    "    print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05c78a-4729-4b33-a667-4d2fad24b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.601 | Train Acc: 66.47% | Train F1: 0.586\n",
      "\tVal. Loss: 0.566 | Val. Acc: 68.96% | Val. F1: 0.577\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02\n",
      "\tTrain Loss: 0.560 | Train Acc: 70.06% | Train F1: 0.651\n",
      "\tVal. Loss: 0.544 | Val. Acc: 70.60% | Val. F1: 0.618\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03\n",
      "\tTrain Loss: 0.538 | Train Acc: 71.63% | Train F1: 0.671\n",
      "\tVal. Loss: 0.521 | Val. Acc: 72.64% | Val. F1: 0.669\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04\n",
      "\tTrain Loss: 0.518 | Train Acc: 72.83% | Train F1: 0.685\n",
      "\tVal. Loss: 0.501 | Val. Acc: 73.41% | Val. F1: 0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05\n",
      "\tTrain Loss: 0.501 | Train Acc: 73.76% | Train F1: 0.698\n",
      "\tVal. Loss: 0.488 | Val. Acc: 74.32% | Val. F1: 0.697\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06\n",
      "\tTrain Loss: 0.488 | Train Acc: 74.48% | Train F1: 0.706\n",
      "\tVal. Loss: 0.474 | Val. Acc: 75.35% | Val. F1: 0.712\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4464:  13%|█▎        | 754/5665 [17:31<1:53:00,  1.38s/it]"
     ]
    }
   ],
   "source": [
    "# Start training with the best hyperparameters\n",
    "num_epochs = 10\n",
    "training_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29b1fa-9f94-404c-b161-97753ffed60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
