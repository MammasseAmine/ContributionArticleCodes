{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820362ef-2cfd-47a4-a00a-611cbe8caae2",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8764fe5b-b3a1-4446-b6db-0309ccd142f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29bae57-e01d-43c8-baf0-6b65f47e6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from bs4 import BeautifulSoup\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch.ao.quantization as quantization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e138e31-f2af-4fc6-8a10-fcfd3815ad06",
   "metadata": {},
   "source": [
    "# ADD THE SEED (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ac6c50-6189-493e-9a83-df028b2a0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42  \n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Ensure deterministic behavior in PyTorch (may slow down training)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa968d3-edc3-4b3c-9837-7d19342cb173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               statement  Label\n",
      "0      End of eviction moratorium means millions of A...      0\n",
      "1      The Trump administration worked to free 5,000 ...      0\n",
      "2      In Afghanistan, over 100 billion dollars spent...      0\n",
      "3      A photo shows two COVID-19 patients lying on t...      0\n",
      "4      Its been over 50 years since minimum (wage) an...      0\n",
      "...                                                  ...    ...\n",
      "73039  Mayor Fung wants to punish our childrens educa...      1\n",
      "73040  There are a larger number of shark attacks in ...      0\n",
      "73041  Democrats have now become the party of the [At...      0\n",
      "73042  On lifting the U.S. Cuban embargo and allowing...      1\n",
      "73043  The Department of Veterans Affairs has a manua...      1\n",
      "\n",
      "[73044 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"myEnglishGlobalFakeNewsDataWithoutFeaturesWithoutPreprocessing.csv\"\n",
    "english_df = pd.read_csv(csv_path)\n",
    "english_df.dropna(inplace=True)\n",
    "print(english_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d6e0e8-b517-47e6-89da-55f97ff1ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the English dataset into training and test sets\n",
    "english_train, english_test = train_test_split(english_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2103c2-5024-4acb-aeff-ff126101bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'statement'\n",
    "labels = english_train['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f216c-3078-444c-819e-7e4aadf87041",
   "metadata": {},
   "source": [
    "# Initialize Tokenizers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0bb328-43c5-4b45-a9ac-3c3f187a8f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d672f3b241d74f66ab315b8889cd0f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f93440af4c468b8f0c9debe084d944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration.py:   0%|          | 0.00/7.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- configuration.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17224586deef4cbca108e0b41c0bc74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling.py:   0%|          | 0.00/59.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- modeling.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc0d98b75424dd59dc24d89db5c67d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "byt5_tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-xxl\")\n",
    "en_model = AutoModel.from_pretrained(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84397f19-8b60-4b7d-bb40-d028fcaaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96cf5b8e-95ca-4dc5-acc1-7cf6797284bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewModel(\n",
       "  (embeddings): NewEmbeddings(\n",
       "    (word_embeddings): Embedding(30528, 1024, padding_idx=0)\n",
       "    (rotary_emb): NTKScalingRotaryEmbedding()\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): NewEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x NewLayer(\n",
       "        (attention): NewAttention(\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp): NewGatedMLP(\n",
       "          (up_gate_proj): Linear(in_features=1024, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act_fn): GELUActivation()\n",
       "          (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move en to device\n",
    "en_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc201f1c-ab47-49e5-9045-591d3b3dbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, model):\n",
    "        self.texts = texts.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        # Tokenize the text with truncation but no padding\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            padding=False,  # No padding here (dynamic padding in collate_fn)\n",
    "            truncation=True,  # Truncate to max_length\n",
    "            max_length=512  # Set a maximum length (in bytes)\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # Shape [seq_len]\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)  # Shape [seq_len]\n",
    "\n",
    "        # Move inputs to the same device as the model\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        # Get embeddings from the model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n",
    "            embeddings = outputs.last_hidden_state.squeeze(0)  # Shape [seq_len, hidden_dim]\n",
    "\n",
    "        # Move data back to CPU for DataLoader\n",
    "        embeddings = embeddings.cpu()\n",
    "        attention_mask = attention_mask.cpu()\n",
    "\n",
    "        return {\n",
    "            'embeddings': embeddings,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7482ed1e-3527-40e4-be79-b53c4cc0529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    embeddings_list = [item['embeddings'] for item in batch]\n",
    "    attention_masks_list = [item['attention_mask'] for item in batch]\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "\n",
    "    max_seq_len = max([embeddings.size(0) for embeddings in embeddings_list])\n",
    "\n",
    "    batch_size = len(batch)\n",
    "    hidden_dim = embeddings_list[0].size(1)\n",
    "    padded_embeddings = torch.zeros(batch_size, max_seq_len, hidden_dim)\n",
    "    padded_attention_masks = torch.zeros(batch_size, max_seq_len, dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        seq_len = embeddings_list[i].size(0)\n",
    "        padded_embeddings[i, :seq_len, :] = embeddings_list[i]\n",
    "        padded_attention_masks[i, :seq_len] = attention_masks_list[i]\n",
    "\n",
    "    return {\n",
    "        'embeddings': padded_embeddings,\n",
    "        'attention_mask': padded_attention_masks,\n",
    "        'labels': labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bbe3d9-4d39-47bb-9fdc-56495b31af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fourier Positional Encoding\n",
    "class FourierPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, temperature=10000):\n",
    "        super(FourierPositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.register_buffer(\n",
    "            'freq_bands',\n",
    "            torch.linspace(0, 1, steps=d_model // 2) * temperature\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        positions = torch.arange(seq_len, dtype=torch.float, device=x.device).unsqueeze(-1)  # Shape [seq_len, 1]\n",
    "        proj = positions * self.freq_bands  # Shape [seq_len, d_model/2]\n",
    "        sin_encoding = torch.sin(proj)\n",
    "        cos_encoding = torch.cos(proj)\n",
    "        encoding = torch.cat([sin_encoding, cos_encoding], dim=-1)\n",
    "        encoding = encoding.unsqueeze(0)  # Shape [1, seq_len, d_model]\n",
    "        return x + encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "135be25b-0ce8-4b3d-af2e-2c56ce06172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model components\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = (normalized_shape,)\n",
    "        self.normalized_shape = tuple(normalized_shape)\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "        if self.elementwise_affine:\n",
    "            self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "            self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dims = tuple(-(i + 1) for i in range(len(self.normalized_shape)))\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        var = x.var(dim=dims, unbiased=False, keepdim=True)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        if self.elementwise_affine:\n",
    "            x = x * self.weight + self.bias\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23eacf1-e13f-4ef0-9690-7ab76f6a48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super(MultiScaleAttention, self).__init__()\n",
    "        self.nhead = nhead\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None, key_padding_mask=None):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # Transform to query, key, value\n",
    "        q = self.query(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)  # [B, nhead, T, d_head]\n",
    "        k = self.key(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)\n",
    "        v = self.value(x).view(B, T, self.nhead, C // self.nhead).transpose(1, 2)\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(k.size(-1))  # [B, nhead, T, T]\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # Apply key_padding_mask if provided\n",
    "        if key_padding_mask is not None:\n",
    "            # key_padding_mask shape: [B, T] -> [B, 1, 1, T]\n",
    "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_scores = attn_scores.masked_fill(key_padding_mask, float('-inf'))\n",
    "\n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Apply attention to values\n",
    "        attn_output = torch.matmul(attn_weights, v)  # [B, nhead, T, d_head]\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        # Final projection\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d169de8-08ce-4168-a390-5abd86f3ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01217f5-070d-48fc-bb72-ce262e6eb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiScaleAttention(d_model, nhead, dropout)\n",
    "        self.ffn = FeedForwardNetwork(d_model, dim_feedforward, dropout)\n",
    "        self.norm1 = LayerNormalization(d_model)\n",
    "        self.norm2 = LayerNormalization(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src2 = self.self_attn(src)\n",
    "        src = src + self.dropout(src2)  # Residual connection\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.ffn(src)\n",
    "        src = src + self.dropout(src2)  # Residual connection\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "        return src\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, num_layers, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175319e2-7672-4ffe-b119-5f466c9775c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, dropout_rate=0.3):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(input_dim, input_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_dim // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf76c4e-3daa-4d6f-906d-898092ef947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, hidden_dim=256, num_classes=2, num_encoder_layers=6):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.quant = torch.ao.quantization.QuantStub()  # Add QuantStub\n",
    "        self.pos_encoder = FourierPositionalEncoding(embedding_dim)\n",
    "        self.encoder = Encoder(embedding_dim, nhead=8, dim_feedforward=hidden_dim * 6, num_layers=num_encoder_layers)\n",
    "        self.classifier = ClassifierHead(embedding_dim, num_classes)\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()  # Add DeQuantStub\n",
    "\n",
    "    def forward(self, embeddings, attention_mask):\n",
    "        # Apply quantization\n",
    "        embeddings = self.quant(embeddings)\n",
    "        \n",
    "        # Apply positional encoding\n",
    "        embeddings = self.pos_encoder(embeddings)\n",
    "        \n",
    "        # Create src_key_padding_mask from attention_mask\n",
    "        src_key_padding_mask = attention_mask == 0\n",
    "        \n",
    "        # Pass through the encoder\n",
    "        encoder_output = self.encoder(embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Masked mean pooling\n",
    "        masked_encoder_output = encoder_output * attention_mask.unsqueeze(-1)\n",
    "        sum_embeddings = masked_encoder_output.sum(dim=1)\n",
    "        lengths = attention_mask.sum(dim=1).unsqueeze(-1)\n",
    "        pooled_output = sum_embeddings / lengths\n",
    "        \n",
    "        # Classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Dequantize the output\n",
    "        logits = self.dequant(logits)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a07f4f3a-a69a-46dc-9333-74a7210bf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined training data into training and validation sets\n",
    "def split_data(texts, labels, tokenizer, model, train_size=0.8, val_size=0.2, batch_size=64):\n",
    "    assert train_size + val_size == 1, \"Split proportions must sum to 1.\"\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset = FakeNewsDataset(texts, labels, tokenizer, model)\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_len = int(train_size * len(dataset))\n",
    "    val_len = len(dataset) - train_len\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
    "    \n",
    "    # Create DataLoaders with the custom collate function\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=custom_collate_fn\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6146b221-3836-4bb3-b80d-354ab292f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = split_data(\n",
    "    english_train['statement'], english_train['Label'],\n",
    "    byt5_tokenizer, en_model, train_size=0.8, val_size=0.2,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10f767db-efb7-4f03-af02-94b2e41c5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_test_dataset = FakeNewsDataset(english_test['statement'], english_test['Label'], byt5_tokenizer, en_model)\n",
    "english_test_dataloader = DataLoader(english_test_dataset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e448b055-df17-48c1-b1af-8c7fc8c08433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (quant): QuantStub()\n",
       "  (pos_encoder): FourierPositionalEncoding()\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (self_attn): MultiScaleAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ffn): FeedForwardNetwork(\n",
       "          (linear1): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "          (activation): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ClassifierHead(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the model and move it to device\n",
    "model = CombinedModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c99f4cd-2428-4d23-a260-f8adccce6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "def setup_optimizer_and_scheduler(model, learning_rate=2e-5, step_size=7, gamma=0.1, weight_decay=0.01):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss function for binary classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer, scheduler = setup_optimizer_and_scheduler(model)\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Initialize GradScaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Wrap the dataloader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        embeddings = batch['embeddings'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use autocast for mixed precision (CUDA)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(embeddings, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Scale the loss and backpropagate\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate loss and predictions\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        # Update the progress bar description with the current loss\n",
    "        progress_bar.set_description(f\"Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average loss and metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return avg_loss, accuracy, f1, precision, recall, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76e07cd6-9580-4b4a-9943-1787bfa744d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            embeddings = batch['embeddings'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(embeddings, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return avg_loss, accuracy, f1, precision, recall, specificity, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43884c75-f68f-4181-af53-ce66e535f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, num_epochs, device, patience=5):\n",
    "    best_val_f1 = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss, train_accuracy, train_f1, train_precision, train_recall, train_specificity = train_one_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        val_loss, val_accuracy, val_f1, val_precision, val_recall, val_specificity, val_preds, val_labels = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print training and validation metrics\n",
    "        print(f\"Epoch: {epoch+1:02}\")\n",
    "        print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}% | Train F1: {train_f1:.3f} | Train Precision: {train_precision:.3f} | Train Recall: {train_recall:.3f} | Train Specificity: {train_specificity:.3f}\")\n",
    "        print(f\"\\tVal. Loss: {val_loss:.3f} | Val. Acc: {val_accuracy*100:.2f}% | Val. F1: {val_f1:.3f} | Val. Precision: {val_precision:.3f} | Val. Recall: {val_recall:.3f} | Val. Specificity: {val_specificity:.3f}\")\n",
    "\n",
    "        # Check for improvement in validation F1 score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "            # Save the best model checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "                'val_preds': val_preds,\n",
    "                'val_labels': val_labels,\n",
    "            }, 'best_model_checkpoint.pth')\n",
    "            print(\"\\tModel saved!\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "                'val_preds': val_preds,\n",
    "                'val_labels': val_labels,\n",
    "            }, 'no_improve_model_checkpoint.pth')\n",
    "            print(\"\\t No Improve Model saved!\")\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs.\")\n",
    "                break\n",
    "\n",
    "    print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb23d66-b682-47d7-aee2-823177857b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.527 | Train Acc: 71.49% | Train F1: 0.689 | Train Precision: 0.724 | Train Recall: 0.656 | Train Specificity: 0.769\n",
      "\tVal. Loss: 0.397 | Val. Acc: 80.20% | Val. F1: 0.790 | Val. Precision: 0.806 | Val. Recall: 0.774 | Val. Specificity: 0.827\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02\n",
      "\tTrain Loss: 0.357 | Train Acc: 80.93% | Train F1: 0.790 | Train Precision: 0.839 | Train Recall: 0.745 | Train Specificity: 0.868\n",
      "\tVal. Loss: 0.327 | Val. Acc: 82.46% | Val. F1: 0.815 | Val. Precision: 0.824 | Val. Recall: 0.807 | Val. Specificity: 0.841\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03\n",
      "\tTrain Loss: 0.327 | Train Acc: 82.61% | Train F1: 0.810 | Train Precision: 0.851 | Train Recall: 0.773 | Train Specificity: 0.875\n",
      "\tVal. Loss: 0.320 | Val. Acc: 83.55% | Val. F1: 0.830 | Val. Precision: 0.824 | Val. Recall: 0.836 | Val. Specificity: 0.835\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04\n",
      "\tTrain Loss: 0.307 | Train Acc: 83.82% | Train F1: 0.826 | Train Precision: 0.855 | Train Recall: 0.799 | Train Specificity: 0.874\n",
      "\tVal. Loss: 0.287 | Val. Acc: 84.96% | Val. F1: 0.838 | Val. Precision: 0.866 | Val. Recall: 0.813 | Val. Specificity: 0.884\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05\n",
      "\tTrain Loss: 0.290 | Train Acc: 85.17% | Train F1: 0.841 | Train Precision: 0.866 | Train Recall: 0.818 | Train Specificity: 0.883\n",
      "\tVal. Loss: 0.278 | Val. Acc: 85.69% | Val. F1: 0.844 | Val. Precision: 0.883 | Val. Recall: 0.809 | Val. Specificity: 0.901\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06\n",
      "\tTrain Loss: 0.274 | Train Acc: 85.89% | Train F1: 0.849 | Train Precision: 0.872 | Train Recall: 0.827 | Train Specificity: 0.888\n",
      "\tVal. Loss: 0.273 | Val. Acc: 86.07% | Val. F1: 0.848 | Val. Precision: 0.892 | Val. Recall: 0.808 | Val. Specificity: 0.910\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07\n",
      "\tTrain Loss: 0.264 | Train Acc: 86.55% | Train F1: 0.857 | Train Precision: 0.875 | Train Recall: 0.839 | Train Specificity: 0.890\n",
      "\tVal. Loss: 0.263 | Val. Acc: 86.98% | Val. F1: 0.864 | Val. Precision: 0.866 | Val. Recall: 0.863 | Val. Specificity: 0.876\n",
      "\tModel saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08\n",
      "\tTrain Loss: 0.253 | Train Acc: 87.06% | Train F1: 0.863 | Train Precision: 0.880 | Train Recall: 0.845 | Train Specificity: 0.894\n",
      "\tVal. Loss: 0.259 | Val. Acc: 87.08% | Val. F1: 0.862 | Val. Precision: 0.883 | Val. Recall: 0.842 | Val. Specificity: 0.897\n",
      "\t No Improve Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09\n",
      "\tTrain Loss: 0.241 | Train Acc: 87.71% | Train F1: 0.870 | Train Precision: 0.885 | Train Recall: 0.855 | Train Specificity: 0.898\n",
      "\tVal. Loss: 0.261 | Val. Acc: 86.86% | Val. F1: 0.852 | Val. Precision: 0.926 | Val. Recall: 0.789 | Val. Specificity: 0.942\n",
      "\t No Improve Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Loss: 0.232 | Train Acc: 88.16% | Train F1: 0.874 | Train Precision: 0.892 | Train Recall: 0.857 | Train Specificity: 0.904\n",
      "\tVal. Loss: 0.248 | Val. Acc: 87.46% | Val. F1: 0.867 | Val. Precision: 0.885 | Val. Recall: 0.849 | Val. Specificity: 0.899\n",
      "\tModel saved!\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  \n",
    "training_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3601d932-3c8e-4e6b-b47c-324f8fb8cd2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:51:32.024651Z",
     "iopub.status.busy": "2025-03-22T12:51:32.024403Z",
     "iopub.status.idle": "2025-03-22T12:51:32.517616Z",
     "shell.execute_reply": "2025-03-22T12:51:32.516934Z",
     "shell.execute_reply.started": "2025-03-22T12:51:32.024620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load('/kaggle/working/best_model_checkpoint.pth')  # Replace with your checkpoint file name\n",
    "\n",
    "# Load the model state\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Load the optimizer state\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Load the scheduler state (if used)\n",
    "\n",
    "if 'scheduler_state_dict' in checkpoint:\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "# Get the epoch number (if saved in the checkpoint)\n",
    "start_epoch = checkpoint.get('epoch', 0) + 1  # Start from the next epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05879cc-145d-4b53-a215-cb928b39b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  \n",
    "training_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dda7b727-1b01-476c-a97f-3a75b97d2c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:51:32.518608Z",
     "iopub.status.busy": "2025-03-22T12:51:32.518391Z",
     "iopub.status.idle": "2025-03-22T12:51:33.081797Z",
     "shell.execute_reply": "2025-03-22T12:51:33.080863Z",
     "shell.execute_reply.started": "2025-03-22T12:51:32.518582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/kaggle/working/best_model_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18287ced-0f62-4cac-b6c7-e522042fbd7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:52:27.806827Z",
     "iopub.status.busy": "2025-03-22T12:52:27.806525Z",
     "iopub.status.idle": "2025-03-22T12:52:29.838341Z",
     "shell.execute_reply": "2025-03-22T12:52:29.837545Z",
     "shell.execute_reply.started": "2025-03-22T12:52:27.806805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in ONNX format at best_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "# Assuming you have already loaded the best model checkpoint\n",
    "checkpoint = torch.load('best_model_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input with the same shape as the model's input\n",
    "# The input shape should match the expected input of the model\n",
    "# For example, if your model expects embeddings of shape [batch_size, seq_len, embedding_dim]\n",
    "batch_size = 1\n",
    "seq_len = 512  # Adjust based on your model's expected input sequence length\n",
    "embedding_dim = 1024  # Adjust based on your model's embedding dimension\n",
    "\n",
    "dummy_input = torch.randn(batch_size, seq_len, embedding_dim).to(device)\n",
    "dummy_attention_mask = torch.ones(batch_size, seq_len, dtype=torch.long).to(device)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_model_path = \"best_model.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,  # Model to be exported\n",
    "    (dummy_input, dummy_attention_mask),  # Model input (tuple or tensor)\n",
    "    onnx_model_path,  # Output file path\n",
    "    export_params=True,  # Store the trained parameter weights inside the model file\n",
    "    opset_version=11,  # ONNX opset version to export the model to\n",
    "    do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "    input_names=['embeddings', 'attention_mask'],  # Input names\n",
    "    output_names=['logits'],  # Output names\n",
    "    dynamic_axes={  # Dynamic axes for variable-length inputs\n",
    "        'embeddings': {0: 'batch_size', 1: 'seq_len'},  # Batch and sequence length can vary\n",
    "        'attention_mask': {0: 'batch_size', 1: 'seq_len'},  # Batch and sequence length can vary\n",
    "        'logits': {0: 'batch_size'}  # Batch size can vary\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model saved in ONNX format at {onnx_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3bd2d58-544b-45e5-ac1f-0f969cf234af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:52:36.341335Z",
     "iopub.status.busy": "2025-03-22T12:52:36.341023Z",
     "iopub.status.idle": "2025-03-22T12:52:36.651854Z",
     "shell.execute_reply": "2025-03-22T12:52:36.651001Z",
     "shell.execute_reply.started": "2025-03-22T12:52:36.341309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(\"ONNX model is valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8375d-e1c1-4b4b-8b85-d48890e23319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:52:46.452794Z",
     "iopub.status.busy": "2025-03-22T12:52:46.452512Z",
     "iopub.status.idle": "2025-03-22T13:41:50.473099Z",
     "shell.execute_reply": "2025-03-22T13:41:50.472124Z",
     "shell.execute_reply.started": "2025-03-22T12:52:46.452772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate on English test set\n",
    "english_loss, english_accuracy, english_f1, english_precision, english_recall, english_specificity, _, _ = evaluate(model, english_test_dataloader, criterion, device)\n",
    "print(f\"English Test Loss: {english_loss:.3f} | English Test Acc: {english_accuracy*100:.2f}% | English Test F1: {english_f1:.3f} | English Test Precision: {english_precision:.3f} | English Test Recall: {english_recall:.3f} | English Test Specificity: {english_specificity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa9fd1-6f96-4c9c-b81b-beca14b385d9",
   "metadata": {},
   "source": [
    "# Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d7734-5443-4006-8624-baa8e1f1f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "model = quantization.convert(model, inplace=True)\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model.state_dict(), 'quantized_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e868e5-0b19-467f-a95f-b4a6bfc3a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4034f70-34c6-4ff9-a19b-458a9b968959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveSparseEncoder:\n",
    "    def __init__(self, initial_features=1024, target_sparsity=0.1, adaptation_rate=0.01):\n",
    "        self.initial_features = initial_features\n",
    "        self.target_sparsity = target_sparsity\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.feature_importance = torch.ones(initial_features, device=device)\n",
    "        self.feature_mask = torch.ones(initial_features, device=device)\n",
    "        self.selected_features = None\n",
    "        self.feature_history = []\n",
    "        \n",
    "    def update_feature_importance(self, embeddings, labels):\n",
    "        \"\"\"Update feature importance based on mutual information with labels\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Convert to numpy for mutual information calculation\n",
    "            embeddings_np = embeddings.cpu().numpy()\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            \n",
    "            # Calculate mutual information for each feature\n",
    "            mi_scores = mutual_info_classif(embeddings_np, labels_np)\n",
    "            new_importance = torch.tensor(mi_scores, device=device)\n",
    "            \n",
    "            # Exponential moving average update\n",
    "            self.feature_importance = (1 - self.adaptation_rate) * self.feature_importance + \\\n",
    "                                    self.adaptation_rate * new_importance\n",
    "            \n",
    "            # Update feature mask based on target sparsity\n",
    "            k = int(self.initial_features * self.target_sparsity)\n",
    "            top_k_values, top_k_indices = torch.topk(self.feature_importance, k)\n",
    "            self.feature_mask.zero_()\n",
    "            self.feature_mask[top_k_indices] = 1.0\n",
    "            \n",
    "            # Store selected features for analysis\n",
    "            self.selected_features = top_k_indices.cpu().numpy()\n",
    "            self.feature_history.append(self.selected_features)\n",
    "    \n",
    "    def encode(self, embeddings):\n",
    "        \"\"\"Apply sparse encoding to embeddings\"\"\"\n",
    "        return embeddings * self.feature_mask\n",
    "    \n",
    "    def get_active_features(self):\n",
    "        \"\"\"Return indices of currently active features\"\"\"\n",
    "        return torch.nonzero(self.feature_mask).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7081e-083b-42b3-bf32-ed6f77ca48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "     stopwords = {\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', ''\n",
    "}\n",
    "\n",
    "     words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "     keywords = [word for word in words if word not in stopwords and len(word) > 2]\n",
    "     return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deefeff-3f71-46f4-90be-fd85010bf790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_keywords():\n",
    "    url = \"https://google.serper.dev/search?engine=google_news&q=latest&apiKey=a4efc96fdbe0af101682967e30c852ec04aaf725\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching recent news:\", response.status_code)\n",
    "        return []\n",
    "    \n",
    "    response_data = response.json()\n",
    "    keywords = []\n",
    "    \n",
    "    organic_items = response_data.get('organic', [])\n",
    "    for item in organic_items:\n",
    "        keywords.extend(extract_keywords(item.get('title', '') + ' ' + item.get('snippet', '')))\n",
    "\n",
    "    keyword_counts = Counter(keywords)\n",
    "    most_common_keywords = [keyword for keyword, count in keyword_counts.most_common(10)]\n",
    "    \n",
    "    return most_common_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287020f-a3d0-4950-9c72-ac1044fec591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fact_checked_news(keywords):\n",
    "    api_key = 'AIzaSyB8CWmQx1lxf_ByZiCo7GduINgchV0BLOc'\n",
    "    results = []\n",
    "\n",
    "    for query in keywords:\n",
    "        encoded_query = requests.utils.quote(query)\n",
    "        url = f'https://factchecktools.googleapis.com/v1alpha1/claims:search?query={encoded_query}&key={api_key}'\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'claims' in data:\n",
    "                for claim in data['claims']:\n",
    "                    for review in claim.get('claimReview', []):\n",
    "                        if review.get('languageCode') == 'ar':\n",
    "                            results.append({\n",
    "                                'text': claim.get('text', ''),\n",
    "                                'rating': review.get('textualRating', ''),\n",
    "                                'date': review.get('reviewDate', ''),\n",
    "                                'url': review.get('url', '')\n",
    "                            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa048b-36e6-4c05-ade7-9512959ec4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for news articles\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b28418-e153-42ac-81b5-0b827619715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Combined Model with Sparse Encoding\n",
    "class AdaptiveSparseModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, hidden_dim=256, num_classes=2, num_encoder_layers=12):\n",
    "        super(AdaptiveSparseModel, self).__init__()\n",
    "        self.sparse_encoder = AdaptiveSparseEncoder(embedding_dim)\n",
    "        self.pos_encoder = FourierPositionalEncoding(embedding_dim)  # From your original code\n",
    "        self.encoder = Encoder(embedding_dim, nhead=8, dim_feedforward=hidden_dim * 6, \n",
    "                             num_layers=num_encoder_layers)  # From your original code\n",
    "        self.classifier = ClassifierHead(embedding_dim, num_classes)  # From your original code\n",
    "        \n",
    "    def forward(self, embeddings, attention_mask, labels=None, training=True):\n",
    "        # Apply sparse encoding\n",
    "        if training and labels is not None:\n",
    "            self.sparse_encoder.update_feature_importance(embeddings.mean(dim=1), labels)\n",
    "        \n",
    "        sparse_embeddings = self.sparse_encoder.encode(embeddings)\n",
    "        \n",
    "        # Apply positional encoding\n",
    "        pos_embeddings = self.pos_encoder(sparse_embeddings)\n",
    "        \n",
    "        # Create padding mask\n",
    "        src_key_padding_mask = attention_mask == 0\n",
    "        \n",
    "        # Pass through encoder\n",
    "        encoder_output = self.encoder(pos_embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Masked mean pooling\n",
    "        masked_encoder_output = encoder_output * attention_mask.unsqueeze(-1)\n",
    "        sum_embeddings = masked_encoder_output.sum(dim=1)\n",
    "        lengths = attention_mask.sum(dim=1).unsqueeze(-1)\n",
    "        pooled_output = sum_embeddings / lengths\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603964c-ee25-484e-a540-233d58f49900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC:\n",
    "    def __init__(self, model, dataloader, criterion, device):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.fisher_matrix = None\n",
    "        self.optimal_params = None\n",
    "\n",
    "    def compute_fisher_information(self):\n",
    "        self.model.eval()\n",
    "        fisher_matrix = {name: torch.zeros_like(param) for name, param in self.model.named_parameters()}\n",
    "\n",
    "        for batch in self.dataloader:\n",
    "            # Extract inputs from the batch\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "\n",
    "            # Compute embeddings using en\n",
    "            with torch.no_grad():\n",
    "                outputs = en_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                embeddings = outputs.last_hidden_state\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            # Forward pass through the model\n",
    "            logits = self.model(embeddings, attention_mask)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Accumulate the Fisher information\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if param.grad is not None:  # Avoid parameters without gradients\n",
    "                    fisher_matrix[name] += param.grad.data ** 2 / len(self.dataloader)\n",
    "\n",
    "        self.fisher_matrix = fisher_matrix\n",
    "\n",
    "\n",
    "    def save_optimal_params(self):\n",
    "        self.optimal_params = {name: param.clone() for name, param in self.model.named_parameters()}\n",
    "\n",
    "    def ewc_loss(self):\n",
    "        loss = 0\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.fisher_matrix:\n",
    "                loss += (self.fisher_matrix[name] * (param - self.optimal_params[name]) ** 2).sum()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3db92b-c993-4c5b-ab73-a5c0f8c235ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousLearningPipeline:\n",
    "    def __init__(self, model_path='best_model_checkpoint.pth', save_dir='model_checkpoints'):\n",
    "        self.model = AdaptiveSparseModel().to(device)\n",
    "        self.save_dir = save_dir\n",
    "        self.ewc = None  # Initialize EWC as None\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        self.load_checkpoint(model_path)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.best_performance = float('inf')  # Track best loss for saving best model\n",
    "        \n",
    "    def load_checkpoint(self, model_path):\n",
    "        if os.path.exists(model_path):\n",
    "            checkpoint = torch.load(model_path)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'best_performance' in checkpoint:\n",
    "                self.best_performance = checkpoint['best_performance']\n",
    "            print(f\"Loaded model checkpoint from {model_path}\")\n",
    "        else:\n",
    "            print(f\"No checkpoint found at {model_path}, starting with fresh model\")\n",
    "    \n",
    "    def save_checkpoint(self, performance_metric, is_best=False):\n",
    "        \"\"\"Save model checkpoint with timestamp and performance metric\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Prepare checkpoint data\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'feature_importance': self.model.sparse_encoder.feature_importance,\n",
    "            'feature_mask': self.model.sparse_encoder.feature_mask,\n",
    "            'best_performance': performance_metric,\n",
    "            'timestamp': timestamp,\n",
    "        }\n",
    "        if self.ewc:\n",
    "            checkpoint['fisher_matrix'] = self.ewc.fisher_matrix\n",
    "            checkpoint['optimal_params'] = self.ewc.optimal_params\n",
    "\n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.save_dir, f'checkpoint_{timestamp}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "        # Save best model if this is the best performance\n",
    "        if is_best:\n",
    "            best_model_path = os.path.join(self.save_dir, 'best_model_checkpoint.pth')\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"Saved best model to {best_model_path}\")\n",
    "\n",
    "    def analyze_feature_adaptation(self):\n",
    "            \"\"\"Analyze how features have adapted over time\"\"\"\n",
    "            feature_history = self.model.sparse_encoder.feature_history\n",
    "            if len(feature_history) > 1:\n",
    "                feature_stability = np.zeros(len(feature_history) - 1)\n",
    "                for i in range(len(feature_history) - 1):\n",
    "                    feature_stability[i] = len(set(feature_history[i]) & set(feature_history[i + 1])) / \\\n",
    "                                    len(feature_history[i])\n",
    "                return {\n",
    "                    'feature_stability': feature_stability.mean(),\n",
    "                    'active_features': len(self.model.sparse_encoder.get_active_features()),\n",
    "                    'importance_stats': {\n",
    "                        'mean': float(self.model.sparse_encoder.feature_importance.mean()),\n",
    "                        'std': float(self.model.sparse_encoder.feature_importance.std())\n",
    "                    }\n",
    "                }\n",
    "            return None\n",
    "    \n",
    "    def predict_with_confidence(self, text):\n",
    "            \"\"\"Make prediction with confidence scores and feature importance analysis\"\"\"\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Tokenize and get embeddings\n",
    "                inputs = byt5_tokenizer(text, return_tensors='pt', padding=True, truncation=True, \n",
    "                                   max_length=512).to(device)\n",
    "                mpnet_outputs = en_model(**inputs)\n",
    "                embeddings = mpnet_outputs.last_hidden_state\n",
    "            \n",
    "                # Get prediction\n",
    "                logits = self.model(embeddings, inputs['attention_mask'], training=False)\n",
    "                probabilities = F.softmax(logits, dim=1)\n",
    "                prediction = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "                # Get active features for this prediction\n",
    "                active_features = self.model.sparse_encoder.get_active_features()\n",
    "            \n",
    "                return {\n",
    "                    'prediction': prediction.item(),\n",
    "                    'confidence': float(probabilities.max()),\n",
    "                    'active_features_count': len(active_features),\n",
    "                    'top_feature_indices': active_features[:10].cpu().tolist()\n",
    "                }\n",
    "\n",
    "    def update_model(self, new_texts, new_labels):\n",
    "        \"\"\"Update model with new data and save checkpoints\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        # Create dataset from new examples\n",
    "        dataset = NewsDataset(new_texts, new_labels, byt5_tokenizer)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Get embeddings\n",
    "            with torch.no_grad():\n",
    "                outputs = en_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                embeddings = outputs.last_hidden_state\n",
    "            \n",
    "            # Forward pass with labels for feature adaptation\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(embeddings, attention_mask, labels, training=True)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            \n",
    "            # Add EWC loss if applicable\n",
    "            if self.ewc:\n",
    "                loss += self.ewc.ewc_loss()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Calculate average loss\n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')\n",
    "        \n",
    "        # Save checkpoint if this is the best performance\n",
    "        is_best = avg_loss < self.best_performance\n",
    "        if is_best:\n",
    "            self.best_performance = avg_loss\n",
    "        \n",
    "        self.save_checkpoint(avg_loss, is_best)\n",
    "        \n",
    "        # Compute Fisher Information and Save Optimal Params for EWC\n",
    "        self.ewc = EWC(self.model, dataloader, self.criterion, device)\n",
    "        self.ewc.compute_fisher_information()\n",
    "        self.ewc.save_optimal_params()\n",
    "        \n",
    "        # Analyze feature adaptation\n",
    "        adaptation_stats = self.analyze_feature_adaptation()\n",
    "        return adaptation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f0cd8-5954-4432-ad75-b1ab9164b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_continuous_pipeline():\n",
    "    pipeline = ContinuousLearningPipeline()\n",
    "    \n",
    "    # Fetch and process new data\n",
    "    keywords = get_recent_keywords()\n",
    "    if keywords:\n",
    "        fact_checked_results = get_fact_checked_news(keywords)\n",
    "        \n",
    "        # Process new examples\n",
    "        new_texts = []\n",
    "        new_labels = []\n",
    "        \n",
    "        print(\"\\nAnalyzing and learning from new claims...\")\n",
    "        for result in fact_checked_results:\n",
    "            text = result['text']\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction_result = pipeline.predict_with_confidence(text)\n",
    "            \n",
    "            print(f\"\\nClaim: {text}\")\n",
    "            print(f\"Model Prediction: {'Fake' if prediction_result['prediction'] == 1 else 'Real'}\")\n",
    "            print(f\"Confidence: {prediction_result['confidence']*100:.2f}%\")\n",
    "            print(f\"Active Features: {prediction_result['active_features_count']}\")\n",
    "            \n",
    "            # Add to training data if we have ground truth\n",
    "            if 'rating' in result:\n",
    "                label = 1 if 'false' in result['rating'].lower() else 0\n",
    "                new_texts.append(text)\n",
    "                new_labels.append(label)\n",
    "                \n",
    "                # Display actual label alongside prediction\n",
    "                print(f\"Actual Label: {'Fake' if label == 1 else 'Real'}\") # Added this line\n",
    "\n",
    "        \n",
    "        # Update model if we have new labeled data\n",
    "        if new_texts:\n",
    "            print(\"\\nUpdating model with new data...\")\n",
    "            adaptation_stats = pipeline.update_model(new_texts, new_labels)\n",
    "            \n",
    "            if adaptation_stats:\n",
    "                print(\"\\nFeature Adaptation Statistics:\")\n",
    "                print(f\"Feature Stability: {adaptation_stats['feature_stability']:.3f}\")\n",
    "                print(f\"Active Features: {adaptation_stats['active_features']}\")\n",
    "                print(f\"Feature Importance - Mean: {adaptation_stats['importance_stats']['mean']:.3f}, \"\n",
    "                      f\"Std: {adaptation_stats['importance_stats']['std']:.3f}\")\n",
    "    \n",
    "    print(\"\\nPipeline completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c99d23-df19-4a17-9f8d-4397ba98b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_continuous_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3344f4-5418-4e82-bd8f-c9613f1fff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_justify_with_lime_and_shap(model, text, tokenizer, en_model):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize and get model prediction\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        mpnet_outputs = en_model(**inputs)\n",
    "        embeddings = mpnet_outputs.last_hidden_state\n",
    "        logits = model(embeddings, inputs['attention_mask'], training=False)  # training=False for AdaptiveSparseModel\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(probabilities, dim=1).item()  # Get the predicted class (0 or 1)\n",
    "\n",
    "    \n",
    "    # SHAP Integration\n",
    "    def model_predict_shap(texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        elif not isinstance(texts, list):\n",
    "            texts = list(texts)\n",
    "        texts = [str(text) for text in texts]\n",
    "\n",
    "        # Tokenize and predict\n",
    "        inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mpnet_outputs = en_model(**inputs)\n",
    "            embeddings = mpnet_outputs.last_hidden_state\n",
    "            logits = model(embeddings, inputs['attention_mask'], training=False)\n",
    "\n",
    "        return logits.cpu().numpy()\n",
    "\n",
    "    # Create SHAP explainer\n",
    "    explainer_shap = shap.Explainer(model_predict_shap, masker=shap.maskers.Text(tokenizer))\n",
    "\n",
    "    # Generate SHAP values\n",
    "    shap_values = explainer_shap([text])\n",
    "\n",
    "    # Display words with SHAP values\n",
    "    words = tokenizer.tokenize(text)\n",
    "    word_shap_values = shap_values.values[0]\n",
    "\n",
    "    print(\"\\nWords with SHAP Values:\")\n",
    "    for word, shap_value in zip(words, word_shap_values):\n",
    "        print(f\"Word: {word}, SHAP Value: {shap_value}\")\n",
    "\n",
    "    # LIME Integration\n",
    "    class_names = ['Real', 'Fake']  # Define class names for LIME visualization\n",
    "\n",
    "    def model_predict_lime(texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        elif not isinstance(texts, list):\n",
    "            texts = list(texts)\n",
    "        texts = [str(text) for text in texts]\n",
    "\n",
    "        # Tokenize and predict\n",
    "        inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mpnet_outputs = en_model(**inputs)\n",
    "            embeddings = mpnet_outputs.last_hidden_state\n",
    "            logits = model(embeddings, inputs['attention_mask'], training=False)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "        return probabilities.cpu().numpy()\n",
    "\n",
    "    # Initialize LIME explainer\n",
    "    explainer_lime = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "    # Generate LIME explanation\n",
    "    lime_explanation = explainer_lime.explain_instance(\n",
    "        text,  # Input text\n",
    "        model_predict_lime,  # Prediction function\n",
    "        num_features=10,  # Number of top words to display\n",
    "        labels=[0, 1]  # Labels to explain (both Real and Fake classes)\n",
    "    )\n",
    "\n",
    "    # Visualize LIME explanation for the predicted class\n",
    "    print(\"\\nLIME Explanation:\")\n",
    "    lime_explanation.show_in_notebook(text=True)\n",
    "\n",
    "    # Save LIME explanation as an HTML file (optional)\n",
    "    lime_explanation.save_to_file('lime_explanation.html')\n",
    "\n",
    "    # Return all results\n",
    "    return {\n",
    "        'prediction': prediction,  # 0 or 1\n",
    "        'probability': probabilities[0][prediction].item(),  # Probability of predicted class\n",
    "        'shap_values': shap_values.values[0].tolist(),  # SHAP values\n",
    "        'shap_base_values': shap_values.base_values[0].tolist(),  # SHAP base values\n",
    "        'lime_explanation': lime_explanation,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77302086-77c6-4fe6-b000-b4e49b66e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaptiveSparseModel() #Or CombinedModel (according to your use case)\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth')['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2ee41-c1bd-4197-9058-177489bbec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_claim = \"\"\"    \"\"\"\n",
    "\n",
    "result = predict_and_justify_with_lime_and_shap(model, new_claim, byt5_tokenizer, en_model)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Claim: {new_claim}\")\n",
    "print(f\"Prediction: {'Fake' if result['prediction'] == 1 else 'Real'}\")\n",
    "print(f\"Probability: {result['probability']:.4f}\")\n",
    "\n",
    "# If LIME explanation is saved, inform the user\n",
    "print(\"\\nLIME explanation saved as 'lime_explanation.html'. Open the file in a browser to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b378da4-8cdd-48ec-b84b-46a9b20a6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reinitialize the scaler\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Step 2: Load the existing checkpoint\n",
    "checkpoint_path = 'best_model_checkpoint.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Step 3: Add the scaler state to the checkpoint\n",
    "checkpoint['scaler_state_dict'] = scaler.state_dict()\n",
    "\n",
    "# Step 4: Save the updated checkpoint\n",
    "torch.save(checkpoint, 'updated_best_model_checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6947192,
     "sourceId": 11137909,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
